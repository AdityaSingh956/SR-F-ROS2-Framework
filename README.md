# <div align="center">Obstacle Detection with RRT Path Planning</div>
![image](https://github.com/WinstonHChou/winter-2024-final-project-team-7/assets/68310078/0ba1c6cb-c9e0-4cf7-905a-f5f16e6bb2ca)
### <div align="center"> Final Project </div>


<div align="center">
    <img src="images\ucsdyellow-car.jpg" height="300"> <img src="images\ucsdcart.png" height="300"><br>

</div>

<hr>
## **Abstract**
We propose developing an autonomous car navigation system using Rapidly-Exploring Random Trees (RRT) with LiDAR for real-time environment mapping and obstacle detection.  Using LiDAR, the system will create a virtual map, enabling the RRT algorithm to identify viable paths around obstacles. A local planner using the Regulated Pure Pursuit Controller will use generated waypoints to guide the car to the target, while real-time controls (x = u̇, v̇, θ̇) will manage the car’s movement. This setup allows for real-time decision-making, enabling the car to differentiate between obstacles on the fly and navigate dynamically toward its goal.

<hr>

## Software

### Laserscan
- Laserscan was another key component to our project which helped enable efficient processing of lidar data for environmental mapping and localization within the ROS2 framework. By using LaserScan data, we were able to detect and visualize the robot’s surroundings in real time, providing a clear 2D representation of spatial layouts. This was also visualized using Rviz2 which optimized visualization settings for clarity.
### Fast_Lio and PointCloud
- The Fast LIO was integral to our project, which helped enable integration of lidar odometry and mapping into the ROS2 framework. This setup allowed the robot to process lidar data in real time and generate accurate odometry for localization  while simultaneously creating detailed point cloud representations of the environment. These point clouds were visualized using the tool, Rviz2 and this helped assess the environment in 3D which also helped the robot to map and detect obstacles.
### Odometry
- The odometry system was crucial for our project, which provided the foundation for accurate localization and navigation within the ROS2 framework. The system allowed the robot to determine its precise position and orientation relative to its environment. This was also visualized using Rviz2, which helped provide a clear and smooth tracking of the robot’s movement.
### SLAM Toolbox
- The SLAM Toolbox incorporates the 2D laser scan data to detect the obstacles. Using TF transforms and laser scan data, it creates an occupancy grid that either marks cells as occupied (100), empty (0), or unknown (-1). In simulation, the SLAM toolbox also provides odometry data that allows the robot to be simultaneously mapped onto the map as well as providing the robot with its real time position.
### RViz
- RViz is a visualization tool that is mainly used for visualizing 3D point cloud data and 2D laser scan data, monitoring occupancy grid data, and visualizing odometry data. It
- allowed us to in real time monitor and debug the mapping and localization of the robot.
### Gazebo
- Gazebo is a simulation software that allows us to model the robots sensors, movements, and environment without using actual physical hardware. In Gazebo, we simulated the use of the LiDAR with our RRT pathing and map generation script as well as testing our controller script to follow the waypoints generated by the RRT pathing. 
